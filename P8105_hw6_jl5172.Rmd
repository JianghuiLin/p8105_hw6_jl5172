---
title: "P8105_hw6_jl5172"
output: github_document
---

```{r,echo=FALSE}
library(tidyverse)
library(modelr)

```

Question 1
```{r}
homicide<-read.csv("homicide-data.csv")
homicide<-homicide %>% 
  mutate(city_state=str_c(city,state,sep=",")) %>% 
  dplyr::filter(city_state!="Dallas,TX",city_state!="Phoenix,AZ",city_state!="Kansas City,MO",city_state!="Tulsa,AL") %>% 
  mutate(resolved=ifelse(disposition=="Closed by arrest",T,F)) %>% 
  mutate(victim_age=as.numeric(victim_age)) %>% 
  mutate(victim_race = tolower(victim_race)) %>% 
  mutate(victim_race =ifelse(victim_race=="white","white","non-white")) %>% 
  mutate(victim_race = fct_relevel(victim_race, "white"))
  


```

Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors. 
```{r}
baltimore<-
  homicide %>% 
  filter(city_state=="Baltimore,MD") 
baltimore_glm = glm(resolved ~ victim_race + victim_age + victim_sex, 
                    data = baltimore, family = binomial())

baltimore_glm %>% 
  broom::tidy() %>% 
  mutate(odds_ratio = exp(estimate),
         conf_low = exp(estimate - std.error * 1.96),
         conf_high = exp(estimate + std.error * 1.96)) %>% 
  filter(term=="victim_racenon-white") %>% 
  dplyr::select(term,odds_ratio,conf_low,conf_high)  %>% 
   knitr::kable(digits = 3) 
```



Run glm for each of the cities in dataset,extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.
```{r}
cities_glm = homicide %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(resolved ~ victim_race + victim_age + victim_sex, data = .x)),
         models = map(models, broom::tidy)) %>% 
  dplyr::select(-data) %>% 
  unnest() %>% 
  mutate(odds_ratio = exp(estimate),
        conf_low = exp(estimate - std.error * 1.96),
         conf_high = exp(estimate + std.error * 1.96)) %>% 
  filter(term == "victim_racenon-white") %>% 
  dplyr::select(city_state,odds_ratio,conf_low,conf_high)
  
  
 cities_glm %>% 
   knitr::kable()
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.
```{r}
cities_glm %>% ggplot(aes(color = reorder(city_state, odds_ratio))) +
  geom_point(aes(x = reorder(city_state, odds_ratio), y = odds_ratio)) +
  geom_errorbar(aes(x = city_state, ymin = conf_low, ymax = conf_high)) +
  coord_flip() + ggtitle("Adjusted Odds Ratio Of Non-white vs White") +
  xlab("City") + ylab("Adjusted odds ratio") + 
  theme(axis.text.y = element_text(size = 6), legend.position = "none") 
```



Question 2
```{r,message=FALSE}
library(broom)
library(dplyr)
library(leaps)
library(HH)
```


```{r}
birth<-read.csv("birthweight.csv") #Load and clean data
skimr::skim(birth) # There is no missing data
birth=
  birth %>% 
  mutate(babysex<-as.factor(babysex), # convert babysex, races and malform column to factor.
         frace<-as.factor(frace),
         mrace<-as.factor(mrace),
         malform<-as.factor(malform)) 
```


```{r}
birth %>% 
  ggplot(aes(x=bwt))+
  geom_histogram()+
  labs(title="Distribution Of Children's Birth Weight")
```
We can tell from the histrogram above that children's birthweights are approximately normally distributed. Therefore, no transformation is needed for further modeling.


I used the 'backward' method here to find desired model with lowest AIC.
AIC estimates the relative information lost by a given model: the less information a model loses, the higher the quality of that model. 
```{r}
mult.fit <- lm(bwt ~ ., data=birth)
step(mult.fit, direction='backward') %>% 
  broom::tidy() 

```

Based on the result, the desired model would contain predictors: babysex + bhead + blength + delwt + fincome +  gaweeks + mheight + parity + ppwt + smoken + + mrace.
The AIC of selected model is 48705.38

  
```{r}
model_1 = lm(bwt ~ babysex + bhead + blength + delwt + fincome +  gaweeks + mheight + parity + ppwt + smoken + mrace, data = birth)
summary(model_1)
```

 
Plot of model residuals against fitted values 
```{r}
birth %>% 
  add_predictions(model_1) %>% 
  add_residuals(model_1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth() + 
  labs(title = "Model Residuals Against Fitted Values",
        x = "Predictions",
        y = "Residuals")
```


Compare my model to two others:
model_2 using length at birth and gestational age as predictors (main effects only)
model_3 using head circumference, length, sex, and all interactions (including the three-way interaction) between these.
```{r}
model_2 = lm(bwt ~ blength + gaweeks, data = birth)
model_3 = lm(bwt ~ babysex + bhead + blength + babysex*bhead + babysex*blength + bhead*blength + babysex*bhead*blength , data = birth)


sum1=summary(model_1)$adj.r.squared
sum2=summary(model_2)$adj.r.squared
sum3=summary(model_3)$adj.r.squared
adj_r_squared<- matrix(c(sum1,sum2,sum3),ncol=1,byrow=TRUE)
colnames(adj_r_squared) <- c("Adjusted R-squared")
rownames(adj_r_squared) <- c("model_1","model_2","model_3")
adj_r_squared<- as.table(adj_r_squared)
adj_r_squared
```

We can tell from table above that adjusted R-squared for model_1 is highest.


Make this comparison in terms of the cross-validated prediction error
```{r}
cross_validation = 
  crossv_mc(birth, 1000) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(model_1 = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome +  gaweeks + mheight + parity + ppwt + smoken + mrace, data = birth)),
         model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = birth)),
         model_3 = map(train, ~lm(bwt ~ babysex + bhead + blength + babysex*bhead + babysex*blength + bhead*blength + babysex*bhead*blength , data = birth)),
         rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
         rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
         rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))
```


```{r}
cross_validation %>% 
  dplyr::select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + 
  labs(title="RMSE Comparisons Amonf Three Models")
```

According to the violin plot above,the first model has lowest RMSE (root-mean-square error) among three. Low RMSE indicates that first model generally has small differences betweem predicted values and obseved values.Therefore, i would consider the first model as the best model among the three.
